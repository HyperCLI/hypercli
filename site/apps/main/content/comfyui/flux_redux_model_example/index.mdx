---
title: "Flux Redux Model"
description: "Generate images by transferring style from reference images using Flux Redux."
template_id: "flux_redux_model_example"
bundle: "media-image"
output_type: "image"
thumbnail: "/comfyui/flux_redux_model_example/thumbnail.webp"
tags: ["Image to Image", "ControlNet", "Image"]
tutorial_url: "https://docs.comfy.org/tutorials/flux/flux-1-controlnet"
date: "2025-03-01"
models: ["flux1-dev.safetensors", "ae.safetensors"]
---

# Flux Redux Model

![thumbnail](/comfyui/flux_redux_model_example/thumbnail.webp)

## About

[Tutorial](https://comfyanonymous.github.io/ComfyUI_examples/flux/#redux)

## Model Links

**Diffusion model**

- [flux1-dev.safetensors](https://huggingface.co/Comfy-Org/flux1-dev/resolve/main/flux1-dev.safetensors)

**Text encoder**

- [clip_l.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors)
- [t5xxl_fp16.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors) or [t5xxl_fp8_e4m3fn.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn.safetensors)

**CLIP Vision**

- [sigclip_vision_patch14_384.safetensors](https://huggingface.co/Comfy-Org/sigclip_vision_384/resolve/main/sigclip_vision_patch14_384.safetensors)

**Style model**

- [flux1-redux-dev.safetensors](https://huggingface.co/Comfy-Org/Flux1-Redux-Dev/resolve/main/flux1-redux-dev.safetensors)

**VAE**
- [ae.safetensors](https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/resolve/main/split_files/vae/ae.safetensors)

Tip: You can set the weight_dtype above to one of the fp8 types if you have memory issues.

**Models save location**

```
ComfyUI/
├── models/
│   ├── diffusion_models/
│   │   └─── flux1-dev.safetensors
│   ├── style_models/
│   │   └─── flux1-redux-dev.safetensors
│   ├── text_encoders/
│   │   ├── clip_l.safetensors
│   │   └─── t5xxl_fp16.safetensors or t5xxl_fp8_e4m3fn.safetensors
│   ├── clip_vision/
│   │   └── sigclip_vision_patch14_384.safetensors
│   └── vae/
│       └── ae.safetensors
```

**Note: About Flux redux**
## Flux Redux (by Black Forest Labs)

**Key Features**
- **No Prompt Required**: Extracts style features directly from input images to generate image variations, no text prompts needed.
- **Multi-Image Blending Support**: Blends styles of multiple input images for more creative possibilities.
- **Good Integration**: Seamlessly fits into complex workflows; enables image restyling via prompts.
- **Advanced Performance**: Excels in image variation generation, producing high-quality variations efficiently.

**Note: About prompt**
Even without a prompt, this model can still apply the image styles from the reference images.

The redux model lets you prompt with images. It can be used with any Flux1 dev or schnell model workflow.

You can chain multiple "Apply Style Model" nodes if you want to mix multiple images together.

The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.

## Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `width` | int | `1024` | Output width in pixels |
| `height` | int | `1024` | Output height in pixels |
| `filename_prefix` | string | `ComfyUI` | Output filename prefix |

## Example Prompt

```
A girl is walking in the natural wilderness.
```

## Usage

```bash
c3 comfyui run flux_redux_model_example \
  --prompt "your prompt here" \
  --output my_output \
  --width 1024 \
  --height 1024
```

## Required Models

- [flux1-dev.safetensors](https://huggingface.co/Comfy-Org/flux1-dev/resolve/main/flux1-dev.safetensors) (UNETLoader)
- [ae.safetensors](https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/resolve/main/split_files/vae/ae.safetensors) (VAELoader)
