---
title: comfyui
description: Run ComfyUI workflows on GPU
---

Run ComfyUI image and video generation workflows on GPU instances.

## Install Templates

ComfyUI commands require workflow templates:

```bash
pip install comfyui-workflow-templates comfyui-workflow-templates-media-image
```

## List Templates

```bash
hyper comfyui templates
```

Shows available workflow templates organized by bundle.

## Show Template

```bash
hyper comfyui show <template>
```

Displays template structure including input nodes, samplers, and outputs.

### Options

| Option | Short | Description |
|--------|-------|-------------|
| `--json` | `-j` | Output full graph JSON |
| `--api` | `-a` | Output API format JSON (what gets sent to ComfyUI) |

### Examples

```bash
# Show template summary
hyper comfyui show image_qwen_image_edit_2511

# Output:
# Template: image_qwen_image_edit_2511
# Nodes: 21 total
#
# LoadImage nodes (inputs):
#   Node 87: wooden_chair.png (bypassed)
#   Node 83: texture_fur.png
#   Node 41: leather_sofa.png
#
# KSampler nodes:
#   Node 65: widgets=[374470990866512, 'randomize', 20, 4, 'euler', 'simple', 1]
# ...

# Get API format for debugging
hyper comfyui show video_wan2_2_14B_i2v --api | jq '.["97"]'
```

## Run Workflow

```bash
hyper comfyui run <template> --prompt "your prompt"
```

### Basic Examples

```bash
# Generate an image with Flux Schnell
hyper comfyui run flux_schnell --prompt "a sunset over mountains" --output sunset

# Generate video with Wan 2.2
hyper comfyui run video_wan2_2_14B_t2v --prompt "a cat walking" --output cat_video

# Specify GPU and region
hyper comfyui run flux_dev --prompt "cyberpunk city" -g h100 -r us
```

### Options

| Option | Short | Description |
|--------|-------|-------------|
| `--prompt` | `-p` | Positive prompt (required) |
| `--negative` | `-n` | Negative prompt |
| `--output` | `-o` | Output filename prefix (default: output) |
| `--output-dir` | `-d` | Output directory (default: .) |
| `--seed` | `-s` | Random seed (deterministic results) |
| `--random` | | Use random seed |
| `--width` | `-W` | Image width |
| `--height` | `-H` | Image height |
| `--steps` | | Number of sampling steps |
| `--cfg` | | CFG scale |
| `--gpu` | `-g` | GPU type (default: l40s) |
| `--gpu-count` | `-c` | Number of GPUs (default: 1) |
| `--region` | `-r` | Region code |
| `--timeout` | `-T` | Workflow timeout in seconds (default: 600) |
| `--interruptible/--on-demand` | | Use interruptible or on-demand instances |
| `--num` | `-N` | Number of images to generate |
| `--new` | | Always launch new instance |
| `--instance` | `-i` | Connect to existing job by ID, hostname, or IP |
| `--lb` | | Enable HTTPS load balancer on port |
| `--auth` | | Enable Bearer token auth on load balancer |
| `--stdout` | | Output to stdout instead of TUI |
| `--debug` | | Debug mode with verbose output |
| `--nodes` | | Node-specific params as JSON (see below) |
| `--workflow-json` | | Output workflow JSON and exit (no GPU) |
| `--install-nodes` | | Custom nodes to install (comma-separated) |
| `--auto-install-nodes` | | Auto-detect and install missing custom nodes |

### GPU Selection

```bash
# Use L40s (default, good balance)
hyper comfyui run flux_schnell --prompt "..." -g l40s

# Use H100 for faster generation
hyper comfyui run flux_dev --prompt "..." -g h100

# Use RTX PRO 6000 for video generation
hyper comfyui run video_wan2_2_14B_t2v --prompt "..." -g RTXPRO6000
```

### Batch Generation

Generate multiple images with different seeds:

```bash
# Generate 4 variations
hyper comfyui run flux_schnell --prompt "a forest" --num 4 --output forest

# With specific starting seed
hyper comfyui run flux_schnell --prompt "a forest" --num 4 --seed 12345
```

### Instance Reuse

By default, the CLI reuses existing ComfyUI instances with matching templates:

```bash
# First run - launches new instance
hyper comfyui run flux_schnell --prompt "sunset"

# Second run - reuses same instance (faster startup)
hyper comfyui run flux_schnell --prompt "mountains"

# Force new instance
hyper comfyui run flux_schnell --prompt "ocean" --new
```

### Connect to Existing Instance

```bash
# By job ID
hyper comfyui run flux_schnell --prompt "..." --instance abc123-def456

# By hostname
hyper comfyui run flux_schnell --prompt "..." --instance my-hostname

# By IP address
hyper comfyui run flux_schnell --prompt "..." --instance 192.168.1.1
```

### HTTPS Load Balancer

For secure external access:

```bash
# Enable HTTPS load balancer on port 8188
hyper comfyui run flux_schnell --prompt "..." --lb 8188

# With authentication
hyper comfyui run flux_schnell --prompt "..." --lb 8188 --auth
```

### Debug Mode

For troubleshooting:

```bash
hyper comfyui run flux_schnell --prompt "..." --debug
```

Shows:
- API requests and responses
- Workflow node details
- Detailed error messages

### Node-Specific Parameters

Use `--nodes` to pass parameters directly to specific workflow nodes by ID:

```bash
# Image-to-video with Wan 2.2 (node 97 is LoadImage)
hyper comfyui run video_wan2_2_14B_i2v \
  --prompt "a dancing character" \
  --nodes '{"97": {"image": "input.png"}, "98": {"width": 832, "height": 480, "length": 81}}' \
  --output dance

# First/last frame video (nodes 80 and 89 are LoadImage)
hyper comfyui run video_wan2_2_14B_flf2v \
  --prompt "smooth transition" \
  --nodes '{"80": {"image": "start.png"}, "89": {"image": "end.png"}}' \
  --output transition

# Lip-sync video with HuMo (node 49: image, node 58: audio)
hyper comfyui run video_humo \
  --prompt "person speaking" \
  --nodes '{"49": {"image": "face.png"}, "58": {"audio": "speech.wav"}}' \
  --output talking
```

The `--nodes` option accepts JSON mapping node IDs to input values:
- `image`: For LoadImage nodes (local paths are auto-uploaded)
- `audio`: For LoadAudio nodes
- `text`: For CLIPTextEncode and similar nodes
- `enabled`: Enable a bypassed node (set to `true`)
- `mode`: Node mode (0=active, 2=muted, 4=bypassed)
- Any other key: Set as generic input

### Enabling Bypassed Nodes

Some templates have optional input nodes that are bypassed by default. Use `enabled: true` to activate them:

```bash
# Qwen Image Edit with 3 reference images
# Use `hyper comfyui show` to see which nodes are bypassed
hyper comfyui show image_qwen_image_edit_2509
# Shows: Node 106 (bypassed), Node 108 (bypassed)

# Enable extra input nodes
hyper comfyui run image_qwen_image_edit_2509 \
  --prompt "Transform the subject with these references" \
  --nodes '{
    "78": {"image": "main.jpg"},
    "106": {"enabled": true, "image": "ref1.jpg"},
    "108": {"enabled": true, "image": "ref2.jpg"}
  }' \
  --output edited
```

### Multi-Image Workflows

The `image_qwen_image_edit_2509` and `image_qwen_image_edit_2511` templates support multiple reference images:

```bash
# 2511: Multi-reference style transfer (2 active + 1 bypassed)
hyper comfyui run image_qwen_image_edit_2511 \
  --prompt "Apply the texture to the subject" \
  --nodes '{
    "41": {"image": "subject.jpg"},
    "83": {"image": "texture.jpg"},
    "87": {"enabled": true, "image": "extra_ref.jpg"}
  }' \
  --output styled
```

### Workflow JSON Output

Generate workflow JSON without running (for debugging or inspection):

```bash
# Output workflow JSON to stdout
hyper comfyui run flux_schnell --prompt "test" --output test --workflow-json

# Find node IDs for --nodes parameter
hyper comfyui run video_humo --prompt "test" --output test --workflow-json | \
  jq '[to_entries[] | select(.value.class_type == "LoadImage" or .value.class_type == "LoadAudio") | {id: .key, type: .value.class_type}]'
```

### Output Modes

```bash
# TUI mode (default) - shows logs and status
hyper comfyui run flux_schnell --prompt "..."

# Simple stdout mode
hyper comfyui run flux_schnell --prompt "..." --stdout
```

## Templates Reference

### Image Generation (text-to-image)

| Template | Model | Notes |
|----------|-------|-------|
| `flux_schnell` | Flux Schnell | Fast, 4 steps |
| `image_qwen_image` | Qwen | Excellent text rendering |
| `hidream_i1_full` | HiDream I1 | Highest quality, 50 steps |

### Image Editing (requires image input)

| Template | Model | LoadImage Nodes | Notes |
|----------|-------|-----------------|-------|
| `hidream_e1_full` | HiDream E1 | 13 | Single image |
| `image_qwen_image_edit_2509` | Qwen Edit 2509 | 78, 106*, 108* | Up to 3 images |
| `image_qwen_image_edit_2511` | Qwen Edit 2511 | 41, 83, 87* | Multi-reference |

*Nodes marked with `*` are bypassed by default - use `{"enabled": true}` to activate.

### Video Generation (text-to-video)

| Template | Model | Notes |
|----------|-------|-------|
| `video_wan2_2_14B_t2v` | Wan 2.2 14B | Text-to-video |
| `video_hunyuan_video_1.5_720p_t2v` | Hunyuan 1.5 | 720p video |

### Video Generation (image-to-video)

| Template | Model | LoadImage Nodes |
|----------|-------|-----------------|
| `video_wan2_2_14B_i2v` | Wan 2.2 I2V | 97 |
| `video_wan2_2_14B_flf2v` | Wan 2.2 FLF | 80 (start), 89 (end) |
| `video_wan2_2_14B_animate` | Wan 2.2 Animate | (varies) |

### Video Generation (with audio)

| Template | Model | LoadImage | LoadAudio |
|----------|-------|-----------|-----------|
| `video_humo` | HuMo | 49 | 58 |
| `video_wan2_2_14B_s2v` | Wan 2.2 S2V | (varies) | (varies) |
