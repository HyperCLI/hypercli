---
title: hyper jobs
description: Job management commands
---

## list

List jobs.

```bash
hyper jobs list
hyper jobs list -s running
hyper jobs list -o json
```

**Options:**
- `-s, --state` - Filter by state: `pending`, `running`, `succeeded`, `failed`, `canceled`
- `-o, --output` - Output format: `table` or `json`

## create

Create a GPU job.

```bash
hyper jobs create <image> [options]

# Examples
hyper jobs create nvidia/cuda:12.0 -g l40s -c "python train.py"
hyper jobs create nvidia/cuda:12.0 -g h100 -n 8 -c "torchrun train.py" -f
hyper jobs create myimage -e HF_TOKEN=xxx -p http:8080
```

**Arguments:**
- `image` - Docker image (required)

**Options:**
- `-g, --gpu` - GPU type: `l40s`, `h100`, `a100`, etc. (default: l40s)
- `-n, --count` - Number of GPUs (default: 1)
- `-c, --command` - Command to run
- `-r, --region` - Region code
- `-t, --runtime` - Max runtime in seconds
- `--interruptible/--on-demand` - Use interruptible instances (default: interruptible)
- `-e, --env` - Environment variables (KEY=VALUE), can repeat
- `-p, --port` - Port mappings (name:port), can repeat
- `-f, --follow` - Launch TUI monitor after creation
- `-o, --output` - Output format: `table` or `json`

## get

Get job details.

```bash
hyper jobs get <job_id>
hyper jobs get <job_id> -o json
```

## logs

Get job logs.

```bash
hyper jobs logs <job_id>
hyper jobs logs <job_id> -f   # Stream with TUI
```

**Options:**
- `-f, --follow` - Stream logs with TUI

## metrics

Get GPU metrics.

```bash
hyper jobs metrics <job_id>
hyper jobs metrics <job_id> -w   # Watch live
hyper jobs metrics <job_id> -o json
```

**Options:**
- `-w, --watch` - Watch metrics live
- `-o, --output` - Output format: `table` or `json`

## cancel

Cancel a job.

```bash
hyper jobs cancel <job_id>
```

## exec

Execute a command non-interactively on a running job container. Returns stdout, stderr, and exit code.

```bash
hyper jobs exec <job_id> <command> [--timeout 30]
```

**Arguments:**
- `job_id` — Job ID (full or prefix)
- `command` — Command to execute

**Options:**
- `-t, --timeout` — Timeout in seconds (default: 30)

**Examples:**
```bash
# Check GPU
hyper jobs exec abc123 "nvidia-smi --query-gpu=name,memory.total --format=csv,noheader"
NVIDIA H200, 141120 MiB

# Run a script
hyper jobs exec abc123 "python -c 'import torch; print(torch.cuda.device_count())'"
8

# Check container OS
hyper jobs exec abc123 "cat /etc/os-release | head -3"
PRETTY_NAME="Ubuntu 22.04.5 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
```

Exit code is forwarded to the shell — use `$?` to check success/failure.

<Tip>
For interactive shells, use `hyper jobs shell` instead. `exec` is designed for scripting and automation.
</Tip>

## shell

Open an interactive PTY shell on a running job container via WebSocket.

```bash
hyper jobs shell <job_id> [--shell /bin/bash]
```

**Arguments:**
- `job_id` — Job ID (full or prefix)

**Options:**
- `-s, --shell` — Shell to use (default: `/bin/bash`)

Press **Ctrl+]** to disconnect.

**Example:**
```bash
$ hyper jobs shell abc123
root@container:/app# nvidia-smi
root@container:/app# python train.py
root@container:/app# ^]  # Ctrl+] to exit
```

## extend

Extend job runtime.

```bash
hyper jobs extend <job_id> <seconds>
```
